{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3b2e7e-868a-425d-9581-bb4ac3dd4f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import anndata as an\n",
    "import scanpy as sc\n",
    "import umap\n",
    "import gc\n",
    "\n",
    "from datasets import Dataset, load_from_disk\n",
    "from datasets import load_dataset\n",
    "from geneformer import EmbExtractor\n",
    "\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263bd307-d1d0-42fa-8e24-e4ceb193aee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4104efe8-8e37-4fc3-b597-857453e1672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"/nfs/turbo/umms-indikar/shared/projects/HSC/data/geneformer/fine_tuned_models/geneformer-6L-30M_CellClassifier_cardiomyopathies_220224\"\n",
    "model = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/\"\n",
    "data_path = \"/scratch/indikar_root/indikar1/cstansbu/HSC/geneformer_inputs/iHSC.dataset\"\n",
    "outpath = \"/scratch/indikar_root/indikar1/cstansbu/geneformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05cdd716-edaf-456f-89f2-48810dee42bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iHSC' 'LinNegCD34lowCD164high' 'HSC' 'LinNegCD34PosCD164Pos' 'MPP' 'MLP'\n",
      " 'FB' 'MKP']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>dataset</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[17610, 10632, 3717, 15803, 8008, 1864, 8659, ...</td>\n",
       "      <td>AAACCCAAGGTTACCT_iHSC</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>6558.0</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[19925, 4387, 11310, 19823, 16979, 1806, 5346,...</td>\n",
       "      <td>AAACCCAAGTTGAAGT_iHSC</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>5488.0</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1078, 3546, 17321, 587, 2815, 11814, 8430, 82...</td>\n",
       "      <td>AAACCCAAGTTGTCGT_iHSC</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>4330.0</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[14192, 8674, 16790, 11523, 2044, 8654, 6995, ...</td>\n",
       "      <td>AAACCCACAGAAGCGT_iHSC</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>3442.0</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[17126, 4895, 10601, 1362, 3537, 19999, 12030,...</td>\n",
       "      <td>AAACCCACAGGAGGTT_iHSC</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>14427.0</td>\n",
       "      <td>iHSC</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids                cell_id  \\\n",
       "0  [17610, 10632, 3717, 15803, 8008, 1864, 8659, ...  AAACCCAAGGTTACCT_iHSC   \n",
       "1  [19925, 4387, 11310, 19823, 16979, 1806, 5346,...  AAACCCAAGTTGAAGT_iHSC   \n",
       "2  [1078, 3546, 17321, 587, 2815, 11814, 8430, 82...  AAACCCAAGTTGTCGT_iHSC   \n",
       "3  [14192, 8674, 16790, 11523, 2044, 8654, 6995, ...  AAACCCACAGAAGCGT_iHSC   \n",
       "4  [17126, 4895, 10601, 1362, 3537, 19999, 12030,...  AAACCCACAGGAGGTT_iHSC   \n",
       "\n",
       "  cell_type  n_counts dataset  length  \n",
       "0      iHSC    6558.0    iHSC    2048  \n",
       "1      iHSC    5488.0    iHSC    2048  \n",
       "2      iHSC    4330.0    iHSC    2048  \n",
       "3      iHSC    3442.0    iHSC    2048  \n",
       "4      iHSC   14427.0    iHSC    2048  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_subset_data(data_path: str, num_cells: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"Loads a dataset from disk, selects a subset of cells, and converts it to a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the dataset file.\n",
    "        num_cells (int, optional): Number of cells to include in the subset (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The subset of data as a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    data = load_from_disk(data_path)\n",
    "    if num_cells > len(data):\n",
    "        raise ValueError(f\"Requested subset size ({num_cells}) exceeds dataset length ({len(data)})\")\n",
    "\n",
    "    data_subset = data.select([i for i in range(num_cells)])\n",
    "    df = data_subset.to_pandas()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df = load_and_subset_data(data_path, num_cells=54346)\n",
    "\n",
    "print(df['cell_type'].unique())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7c4cf20-8c1d-401d-949a-86209fc336f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18780"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genes = []\n",
    "\n",
    "for sentence in df['input_ids'].values:\n",
    "    all_genes += list(sentence)\n",
    "\n",
    "len(set(all_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7914c49-deea-4542-8bf8-6aa34e562b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4319f63a-681e-4ca6-9dad-a139b9a3521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adc3a392-c530-4742-9c67-c1ff27bbbdf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 19\u001b[0m\n\u001b[1;32m      8\u001b[0m embex \u001b[38;5;241m=\u001b[39m EmbExtractor(model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                      num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     10\u001b[0m                      max_ncells\u001b[38;5;241m=\u001b[39mn_cells,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m                      nproc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     16\u001b[0m                       )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# extracts embedding from input data\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m embs \u001b[38;5;241m=\u001b[39m \u001b[43membex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_embs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moutpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/emb_extractor.py:560\u001b[0m, in \u001b[0;36mEmbExtractor.extract_embs\u001b[0;34m(self, model_directory, input_data_file, output_directory, output_prefix, output_torch_embs, cell_state)\u001b[0m\n\u001b[1;32m    556\u001b[0m     filtered_input_data \u001b[38;5;241m=\u001b[39m pu\u001b[38;5;241m.\u001b[39mfilter_by_dict(\n\u001b[1;32m    557\u001b[0m         filtered_input_data, cell_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnproc\n\u001b[1;32m    558\u001b[0m     )\n\u001b[1;32m    559\u001b[0m downsampled_data \u001b[38;5;241m=\u001b[39m pu\u001b[38;5;241m.\u001b[39mdownsample_and_sort(filtered_input_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_ncells)\n\u001b[0;32m--> 560\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m layer_to_quant \u001b[38;5;241m=\u001b[39m pu\u001b[38;5;241m.\u001b[39mquant_layers(model) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_layer\n\u001b[1;32m    564\u001b[0m embs \u001b[38;5;241m=\u001b[39m get_embs(\n\u001b[1;32m    565\u001b[0m     model,\n\u001b[1;32m    566\u001b[0m     downsampled_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummary_stat,\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/perturber_utils.py:140\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_type, num_classes, model_directory, mode)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    139\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 140\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/transformers/modeling_utils.py:2692\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2689\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2690\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2691\u001b[0m         )\n\u001b[0;32m-> 2692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "n_cells = 100\n",
    "# 0 for last layer, -1 for second to last\n",
    "layer = 0 \n",
    "\n",
    "# initiate EmbExtractor\n",
    "embex = EmbExtractor(model_type=\"Pretrained\",\n",
    "                     num_classes=0,\n",
    "                     max_ncells=n_cells,\n",
    "                     emb_mode='cell',\n",
    "                     emb_layer=layer,\n",
    "                     emb_label=[\"cell_type\", \"dataset\", \"n_counts\", \"length\"],\n",
    "                     forward_batch_size=30,\n",
    "                     nproc=16,\n",
    "                      )\n",
    "\n",
    "# extracts embedding from input data\n",
    "embs = embex.extract_embs(model,\n",
    "                          data_path,\n",
    "                          outpath,\n",
    "                          \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38955dff-0a2d-4801-94bc-19f27bce9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c87528-a08d-4316-b939-de2d4729acb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3721e36-02bc-460c-a2d1-28cf704d3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a5ee22-17e6-4c78-96c3-d6ca12435bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_to_adata(df: pd.DataFrame, n_dim: int = None) -> an.AnnData:\n",
    "    \"\"\"Converts a Pandas DataFrame with an embedding to an AnnData object.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame with numerical embedding columns and optional metadata columns.\n",
    "        n_dim: The number of dimensions to keep in the embedding. If None, all dimensions are kept.\n",
    "\n",
    "    Returns:\n",
    "        The converted AnnData object.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `n_dim` exceeds the available dimensions in the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    if n_dim is not None and n_dim > df.shape[1]:\n",
    "        raise ValueError(f\"n_dim ({n_dim}) exceeds available dimensions ({df.shape[1]})\")\n",
    "\n",
    "    # Assuming embedding columns are those that are not integers\n",
    "    is_metadata = df.columns.astype(str).str.isdigit()\n",
    "    metadata_df = df.loc[:, ~is_metadata]\n",
    "    embedding_df = df.loc[:, is_metadata]\n",
    "\n",
    "    cell_index = pd.Index([f\"C{x}\" for x in range(df.shape[0])], name='obs_names')\n",
    "\n",
    "    if n_dim is not None:\n",
    "        embedding_df = embedding_df.iloc[:, :n_dim]\n",
    "\n",
    "    var_index = pd.Index([f\"D{x}\" for x in range(embedding_df.shape[1])], name='var_names')\n",
    "\n",
    "    adata = an.AnnData(embedding_df.to_numpy())\n",
    "    adata.obs_names = cell_index\n",
    "    adata.var_names = var_index\n",
    "    adata.obs = metadata_df\n",
    "    return adata\n",
    "\n",
    "    \n",
    "adata = embedding_to_adata(embs, n_dim=50)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da40b1e-3524-4a36-b90a-ee76e15ee814",
   "metadata": {},
   "source": [
    "# PCA of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c72451-d4be-43cd-a971-cb0fb2dba516",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata, min_dist=0.1)\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"cell_type\", \"dataset\"],\n",
    "    ncols=1,\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd8c99-aef9-4309-8c62-1e5a35b522a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24daf09-b35d-4724-b608-fabf1bae785d",
   "metadata": {},
   "source": [
    "# Neighbor Graph (no PCA of embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa3aac-52cf-4969-8aba-9507d13d3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep='X')\n",
    "sc.tl.umap(adata, min_dist=0.1)\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"cell_type\", \"dataset\", \"n_counts\", \"length\"],\n",
    "    ncols=1,\n",
    "    size=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18635751-1446-4f89-a8be-496891b1d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca643e-42c8-4d51-a5cf-d1712f6bfc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc027a-234d-42c9-9abf-35196a7823fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8f0a4-366e-4501-8cdf-6ecc2e466ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c393ed-a81c-43e7-83bc-7e4e525190b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eee760-faa7-4b65-9058-2467a5bd9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(adata.X)\n",
    "\n",
    "adata.obs['UMAP 1'] = embedding[:, 0]\n",
    "adata.obs['UMAP 2'] = embedding[:, 1]\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bcc2e-9ae1-471f-8bc5-4558b6f2a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a920429-3a71-45e9-a213-6ca7d1455d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "sns.scatterplot(data=adata.obs,\n",
    "                x='UMAP 1',\n",
    "                y='UMAP 2',\n",
    "                ec='none',\n",
    "                lw=0.1,\n",
    "                alpha=0.9,\n",
    "                hue='dataset',\n",
    "                s=5)\n",
    "\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "sns.move_legend(plt.gca(), \n",
    "                loc='upper right',\n",
    "                bbox_to_anchor=(1.7, 1))\n",
    "\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbbef48-5325-4b8e-87fa-cf6df9ba9711",
   "metadata": {},
   "source": [
    "# Neighbor Graph (no PCA of embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb8438-b363-4113-851d-3a89e5c8fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"cell_type\", \"dataset\"],\n",
    "    n_cols=1,\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f55e49-8c37-40c6-8062-ded826241b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707dd9c-8335-459e-bd91-faeb571e76ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01843c0f-0c46-4d5f-9587-42e4208d5ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d40fe-29af-474c-b5e2-2c4383518a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_1 = 4\n",
    "comp_2 = 5\n",
    "\n",
    "sns.scatterplot(data=embs,\n",
    "                x=comp_1,\n",
    "                y=comp_2,\n",
    "                ec='none',\n",
    "                lw=0.1,\n",
    "                alpha=0.9,\n",
    "                hue='dataset',\n",
    "                s=5)\n",
    "\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "sns.move_legend(plt.gca(), \n",
    "                loc='upper right',\n",
    "                bbox_to_anchor=(1.7, 1))\n",
    "\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255fd35-e66c-41dd-9e10-a791783e0976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691cfd5-86d2-4aab-96ae-a3af46c0bf71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298cb8e-6608-4cfb-9b00-49dc1652e02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baab1a6-f2aa-426e-8e2d-46692345406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, n_comps=5)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"cell_type\",\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb95f92-f5eb-47a7-8be1-2269e8810e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db772b72-2c63-4103-a8c5-c27b107e7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, n_iterations=2)\n",
    "sc.pl.umap(adata, color=[\"leiden\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf80196-1d40-4b5c-95b3-24b589d052f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8517e-12a2-4b3b-aeb8-dcbe9f9f01d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb54a2-92d6-437e-a600-25970da5b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7c503-eb9f-4897-b929-5c0bb0ba1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=embs,\n",
    "                x=0,\n",
    "                y=1,\n",
    "                hue='dataset',\n",
    "                s=10)\n",
    "\n",
    "sns.move_legend(plt.gca(), \n",
    "                loc='upper right',\n",
    "                bbox_to_anchor=(1.7, 1))\n",
    "\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee40f89-6b88-4d60-9a62-ea1e767e30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123fd075-6f6c-481d-89cf-d80ee5f6ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata)\n",
    "sc.pp.neighbors(adata, n_neighbors=21)\n",
    "sc.tl.umap(adata, min_dist=0.2)\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e3bec-15b2-414f-9a6e-53149465d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, \n",
    "           color=['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf1b9d-c333-4112-b3ec-d3bcb4cd81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1bed4-7eb8-4c50-bf92-1f68033a519f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec5868-ab5f-455c-9dc8-d084a0da551a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48932e-d460-4620-a5b8-f5d2a0011d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = embs.copy()\n",
    "\n",
    "sns.scatterplot(data=df,  \n",
    "                x=0,\n",
    "                y=2,\n",
    "                alpha=0.6,\n",
    "                s=10,\n",
    "                palette=\"Set1\",\n",
    "                # legend=False,\n",
    "                hue='dataset')\n",
    "\n",
    "sns.move_legend(plt.gca(), \n",
    "                loc='upper right',\n",
    "                bbox_to_anchor=(1.4, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579094bf-3b29-4d3b-8b7c-dfb688454fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "geneformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
