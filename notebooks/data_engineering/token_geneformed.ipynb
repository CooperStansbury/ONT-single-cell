{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773ac126-4b16-4d9b-b437-5198c6972133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# env_path = \"/home/cstansbu/miniconda3/envs/scanpy/lib/python3.12/site-packages/\"\n",
    "# sys.path.append(env_path)\n",
    "\n",
    "# for datasets\n",
    "env_path = \"/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/\"\n",
    "sys.path.insert(0, env_path)\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as an\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ecb82a2-44d9-4402-be7d-a73dbde7e8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 8562 × 14972\n",
       "    obs: 'n_genes', 'doublet_score', 'predicted_doublet', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'\n",
       "    var: 'gene_name', 'Chromosome', 'Start', 'End', 'Strand', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'ensembl_id'\n",
       "    uns: 'clusters', 'fb_vs_hsc_up', 'go_annotations', 'hsc_v_fib_up', 'hvg', 'log1p', 'neighbors', 'panglaodb', 'pca', 'scenic_transcription_factors', 'scrublet', 'tabula_sapiens_deg', 'umap', 'v5_tags'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    layers: 'filtered_counts', 'raw_counts'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = \"/scratch/indikar_root/indikar1/cstansbu/HSC/scanpy/clustered.anndata.h5ad\"\n",
    "\n",
    "adata = sc.read_h5ad(fpath)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f130cfa-cc4d-49c9-9091-cfd73370a8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19393"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_gene_map(gene_table_path, gene_type=\"protein_coding\", keys='gene_name', values='gene_id'):\n",
    "    \"\"\"\n",
    "    Loads and filters a gene mapping table from a CSV file.\n",
    "\n",
    "    This function reads a CSV file containing gene information, filters for protein-coding genes\n",
    "    (or other specified types), handles duplicates and missing values, and creates a dictionary \n",
    "    mapping the specified `keys` (e.g., gene names) to the corresponding `values` (e.g., gene IDs).\n",
    "\n",
    "    Args:\n",
    "        gene_table_path (str): Path to the CSV file containing the gene table.\n",
    "        gene_type (str, optional): The type of gene to filter for (default: 'protein_coding').\n",
    "        keys (str, optional): The column name to use as keys in the output dictionary (default: 'gene_name').\n",
    "        values (str, optional): The column name to use as values in the output dictionary (default: 'gene_id').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping gene keys to gene values for protein-coding genes.\n",
    "    \"\"\"\n",
    "    usecols = ['gene_id', 'gene_name', 'gene_biotype']\n",
    "    df = pd.read_csv(gene_table_path, usecols=usecols)\n",
    "\n",
    "    # Filter and clean data in a single chain\n",
    "    df = (\n",
    "        df.drop_duplicates()\n",
    "        .query(\"gene_biotype == @gene_type\")\n",
    "        .dropna(subset=['gene_name', 'gene_id'])\n",
    "    )\n",
    "\n",
    "    return dict(zip(df[keys], df[values]))\n",
    "    \n",
    "gene_table_path = \"/scratch/indikar_root/indikar1/cstansbu/HSC/references/geneTable.csv\"\n",
    "gene_map = load_gene_map(gene_table_path)    \n",
    "len(gene_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809ba80e-a5e9-4747-a690-e22ede115e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATAD3B',\n",
       " 'PRDM16',\n",
       " 'SKI',\n",
       " 'PEX14',\n",
       " 'PLCH2',\n",
       " 'SPSB1',\n",
       " 'HES3',\n",
       " 'PLEKHM2',\n",
       " 'CA6',\n",
       " 'NMNAT1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gene_map.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24f2dba3-91a5-4d16-b6d9-7cd6a13ef36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 8562 × 14972\n",
       "    obs: 'n_genes', 'doublet_score', 'predicted_doublet', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'n_counts'\n",
       "    var: 'ensemble_id'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def skeletonize(adata, gene_map, gene_identifier, gene_column_type, gene_index, counts_layer):\n",
    "    \"\"\"\n",
    "    Creates a simplified AnnData object by filtering genes and mapping identifiers.\n",
    "\n",
    "    This function takes an AnnData object and a gene mapping dictionary. It filters the genes in \n",
    "    the AnnData based on the provided mapping, optionally converting between gene names and Ensembl IDs.\n",
    "    The resulting AnnData object contains only the relevant genes and their associated count data,\n",
    "    along with the original observation metadata.\n",
    "\n",
    "    Args:\n",
    "        adata (anndata.AnnData): The input AnnData object containing gene expression data.\n",
    "        gene_map (dict): A dictionary mapping gene identifiers (keys) to desired values.\n",
    "                            Keys can be either gene names or Ensembl IDs, depending on `gene_column_type`.\n",
    "        gene_identifier (str): The column name in `adata.var` containing the gene identifiers \n",
    "                            (either 'gene_name' or 'ensemble_id').\n",
    "        gene_column_type (str): Indicates the type of gene identifier in the `gene_identifier` column:\n",
    "                            'gene_name' or 'ensemble_id'.\n",
    "        gene_index (str): The column name to use as the gene index in the output AnnData's `.var` attribute.\n",
    "                            Typically 'gene_name' or 'ensemble_id'.\n",
    "        counts_layer (str): The layer name in `adata` to use for count data (default is 'counts').\n",
    "\n",
    "    Returns:\n",
    "        anndata.AnnData: A new AnnData object with:\n",
    "            - `.X`: Count data filtered to the relevant genes.\n",
    "            - `.obs`: Copied from the original `adata`.\n",
    "            - `.var`: Contains the `gene_index` as the index, and the mapped gene identifiers.\n",
    "            - `.obs['n_counts']`: Added (or preserved) to indicate the total counts per cell.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an invalid `gene_column_type` is provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    if gene_column_type == 'gene_name':\n",
    "        var = pd.DataFrame(adata.var[gene_identifier].copy())\n",
    "        var.columns = ['gene_name']\n",
    "        var['ensemble_id'] = var['gene_name'].map(gene_map)\n",
    "        var = var[var['ensemble_id'].notna()]\n",
    "        gene_idx = var.index # use the existing index\n",
    "    elif gene_column_type == 'ensemble_id':\n",
    "        var = pd.DataFrame(adata.var[gene_identifier].copy())\n",
    "        var.columns = ['ensemble_id']\n",
    "        var['gene_name'] = var['ensemble_id'].map(gene_map)\n",
    "        var = var[var['gene_name'].notna()]\n",
    "        gene_idx = var.index # use the existing index\n",
    "    else:\n",
    "        raise ValueError('gene_column_type must be one of: `ensemble_id` or `gene_name`')\n",
    "        \n",
    "    X = adata[:, gene_idx].layers[counts_layer]\n",
    "    ndata = an.AnnData(X)\n",
    "    ndata.obs = adata.obs.copy()\n",
    "    ndata.obs_names = adata.obs_names\n",
    "    \n",
    "    if not 'n_counts' in ndata.obs.columns:\n",
    "        ndata.obs['n_counts'] = X.sum(axis=1)\n",
    "    \n",
    "    ndata.var_names = var[gene_index].values\n",
    "    ndata.var = var.set_index(gene_index)\n",
    "    \n",
    "    return ndata\n",
    "    \n",
    "    \n",
    "test = skeletonize(adata, gene_map,\n",
    "                   gene_identifier='gene_name', \n",
    "                   gene_column_type='gene_name', \n",
    "                   gene_index='gene_name',\n",
    "                   counts_layer=\"raw_counts\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf523160-b953-4241-b93d-543c41d73176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_name</th>\n",
       "      <th>ATAD3B</th>\n",
       "      <th>SKI</th>\n",
       "      <th>PEX14</th>\n",
       "      <th>PLCH2</th>\n",
       "      <th>SPSB1</th>\n",
       "      <th>HES3</th>\n",
       "      <th>PLEKHM2</th>\n",
       "      <th>CA6</th>\n",
       "      <th>NMNAT1</th>\n",
       "      <th>CCDC27</th>\n",
       "      <th>...</th>\n",
       "      <th>CDY1</th>\n",
       "      <th>TSPY4</th>\n",
       "      <th>TSPY9</th>\n",
       "      <th>KDM5D</th>\n",
       "      <th>BPY2C</th>\n",
       "      <th>CDY2B</th>\n",
       "      <th>SRY</th>\n",
       "      <th>VCY</th>\n",
       "      <th>DAZ1</th>\n",
       "      <th>RBMY1E</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGGTTACCT</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGTTGAAGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAAGTTGTCGT</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCACAGAAGCGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCACAGGAGGTT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGCAAGAGGTC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGCATGTGGTT</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGGTATACCCA</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCACGTAGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCGATGCTA</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8562 rows × 14972 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_name         ATAD3B  SKI  PEX14  PLCH2  SPSB1  HES3  PLEKHM2  CA6  \\\n",
       "cell_id                                                                  \n",
       "AAACCCAAGGTTACCT       0    1      0      0      0     0        0    0   \n",
       "AAACCCAAGTTGAAGT       0    0      0      0      0     0        0    0   \n",
       "AAACCCAAGTTGTCGT       0    1      0      0      0     0        0    0   \n",
       "AAACCCACAGAAGCGT       0    0      0      0      0     0        0    0   \n",
       "AAACCCACAGGAGGTT       0    0      0      0      0     0        0    0   \n",
       "...                  ...  ...    ...    ...    ...   ...      ...  ...   \n",
       "TTTGTTGCAAGAGGTC       0    0      0      0      0     0        0    0   \n",
       "TTTGTTGCATGTGGTT       1    0      0      0      0     0        1    0   \n",
       "TTTGTTGGTATACCCA       0    1      0      0      0     0        0    0   \n",
       "TTTGTTGTCACGTAGT       0    0      0      0      0     0        2    0   \n",
       "TTTGTTGTCGATGCTA       0    0      0      0      0     0        0    0   \n",
       "\n",
       "gene_name         NMNAT1  CCDC27  ...  CDY1  TSPY4  TSPY9  KDM5D  BPY2C  \\\n",
       "cell_id                           ...                                     \n",
       "AAACCCAAGGTTACCT       0       1  ...     0      0      0      0      0   \n",
       "AAACCCAAGTTGAAGT       0       0  ...     0      0      1      0      0   \n",
       "AAACCCAAGTTGTCGT       0       0  ...     0      0      0      0      0   \n",
       "AAACCCACAGAAGCGT       0       0  ...     0      0      1      0      0   \n",
       "AAACCCACAGGAGGTT       0       0  ...     0      0      1      1      0   \n",
       "...                  ...     ...  ...   ...    ...    ...    ...    ...   \n",
       "TTTGTTGCAAGAGGTC       0       0  ...     0      0      0      0      0   \n",
       "TTTGTTGCATGTGGTT       0       0  ...     0      0      0      0      0   \n",
       "TTTGTTGGTATACCCA       0       1  ...     0      0      1      0      0   \n",
       "TTTGTTGTCACGTAGT       0       1  ...     0      0      0      0      0   \n",
       "TTTGTTGTCGATGCTA       0       1  ...     0      0      0      0      0   \n",
       "\n",
       "gene_name         CDY2B  SRY  VCY  DAZ1  RBMY1E  \n",
       "cell_id                                          \n",
       "AAACCCAAGGTTACCT      0    0    4     0       0  \n",
       "AAACCCAAGTTGAAGT      0    0    3     0       0  \n",
       "AAACCCAAGTTGTCGT      0    1    1     0       0  \n",
       "AAACCCACAGAAGCGT      0    0    0     0       0  \n",
       "AAACCCACAGGAGGTT      0    0    3     0       0  \n",
       "...                 ...  ...  ...   ...     ...  \n",
       "TTTGTTGCAAGAGGTC      0    0    1     0       0  \n",
       "TTTGTTGCATGTGGTT      0    0    3     0       0  \n",
       "TTTGTTGGTATACCCA      0    0    2     0       0  \n",
       "TTTGTTGTCACGTAGT      0    0    1     0       0  \n",
       "TTTGTTGTCGATGCTA      0    0    5     0       0  \n",
       "\n",
       "[8562 rows x 14972 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0835457c-06ed-4f51-a70a-8afece7d0a8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cbd5bd-5163-4346-959e-6eb1ba8f8564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b88c3-b9e2-498f-9551-bf7db96342c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7248e7-4ca4-4336-b7ef-ee3bb8aaae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['n_counts'] = adata.obs['total_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e941e-fb9d-4368-8ad0-0ba5b116d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gene_median_dict(gene_median_file):\n",
    "    \"\"\"\n",
    "    Loads a gene median dictionary from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        gene_median_file (str): Path to the pickle file containing the gene median dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping gene IDs to their median expression values.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(gene_median_file, \"rb\") as f:\n",
    "        gene_median_dict = pickle.load(f)\n",
    "\n",
    "    return gene_median_dict\n",
    "\n",
    "\n",
    "def load_gene_tokenization(token_dictionary_file):\n",
    "    \"\"\"\n",
    "    Loads gene tokenization data from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        token_dictionary_file (str): Path to the pickle file containing the gene-token dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: Gene-token dictionary (Ensembl ID: token).\n",
    "        list: List of all gene keys (Ensembl IDs).\n",
    "        dict: Dictionary mapping gene keys to True (used for selecting genes later).\n",
    "    \"\"\"\n",
    "\n",
    "    with open(token_dictionary_file, \"rb\") as f:\n",
    "        gene_token_dict = pickle.load(f)\n",
    "\n",
    "    gene_keys = list(gene_token_dict.keys())\n",
    "\n",
    "    # Optimization: Pre-allocate the list for slight performance improvement\n",
    "    genelist_dict = dict.fromkeys(gene_keys, True)\n",
    "\n",
    "    return gene_token_dict, gene_keys, genelist_dict\n",
    "\n",
    "\n",
    "# GENE TOKEN DICT\n",
    "fpath = \"/home/cstansbu/git_repositories/Geneformer/geneformer/token_dictionary.pkl\"\n",
    "gene_token_dict, gene_keys, genelist_dict = load_gene_tokenization(fpath)\n",
    "\n",
    "# GENE MEDIAN DICT\n",
    "fpath = \"/home/cstansbu/git_repositories/Geneformer/geneformer/gene_median_dictionary.pkl\"\n",
    "gene_median_dict = load_gene_median_dict(fpath)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e229eac-3d16-4f42-b810-bdf5ab4f3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_genes(gene_vector, gene_tokens):\n",
    "    \"\"\"Ranks genes based on expression values in descending order.\n",
    "\n",
    "    Args:\n",
    "        gene_vector (numpy.ndarray): Array of gene expression values.\n",
    "        gene_tokens (numpy.ndarray): Array of corresponding gene tokens.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of gene tokens sorted by descending expression value.\n",
    "    \"\"\"\n",
    "    return gene_tokens[np.argsort(-gene_vector)]\n",
    "\n",
    "\n",
    "def tokenize_anndata(adata, genelist_dict, gene_median_dict, \n",
    "                     chunk_size=1000, target_sum=10000, \n",
    "                     counts_column='n_counts', gene_id=\"ensembl_id\"):\n",
    "    \"\"\"\n",
    "    Tokenizes and ranks genes within an AnnData object, optimizing for memory efficiency.\n",
    "\n",
    "    This function processes gene expression data in chunks, applies normalization, and ranks genes\n",
    "    for each cell based on their expression levels. The resulting tokenized and ranked gene\n",
    "    representations, along with cell metadata, are returned.\n",
    "\n",
    "    Args:\n",
    "        adata (AnnData): The AnnData object containing gene expression data.\n",
    "        genelist_dict (dict): Dictionary mapping gene IDs to boolean values indicating relevance.\n",
    "        gene_median_dict (dict): Dictionary mapping gene IDs to their median expression values.\n",
    "        chunk_size (int, optional): Number of cells to process in each chunk (default: 1000).\n",
    "        target_sum (int, optional): Target sum for count normalization (default: 10000).\n",
    "        counts_column (str, optional): The column in `adata.obs` containing cell counts (default: 'n_counts').\n",
    "        gene_id (str, optional): The column in `adata.var` containing gene IDs (default: 'ensembl_id').\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - list: List of tokenized and ranked gene lists for each cell.\n",
    "            - dict: Dictionary containing cell metadata (keys are metadata column names).\n",
    "    \"\"\"\n",
    "    # Filter relevant miRNAs\n",
    "    coding_miRNA_mask = np.array([genelist_dict.get(i, False) for i in adata.var[gene_id]])\n",
    "    coding_miRNA_loc = np.where(coding_miRNA_mask)[0]\n",
    "\n",
    "    # Extract miRNA information\n",
    "    coding_miRNA_ids = adata.var[gene_id][coding_miRNA_loc]\n",
    "    norm_factor_vector = np.array([gene_median_dict[i] for i in coding_miRNA_ids])\n",
    "    coding_miRNA_tokens = np.array([gene_token_dict[i] for i in coding_miRNA_ids])\n",
    "\n",
    "    tokenized_cells = []\n",
    "    file_cell_metadata = {k: [] for k in adata.obs.columns}  # Initialize metadata dict\n",
    "\n",
    "    # Process in chunks for memory efficiency\n",
    "    for chunk_start in range(0, adata.shape[0], chunk_size):\n",
    "        chunk_end = chunk_start + chunk_size\n",
    "        adata_chunk = adata[chunk_start:chunk_end, coding_miRNA_loc]\n",
    "\n",
    "        # Normalize counts\n",
    "        n_counts = adata_chunk.obs[counts_column].values[:, None]\n",
    "        X_norm = adata_chunk.X / n_counts * target_sum / norm_factor_vector\n",
    "        X_norm = sp.csr_matrix(X_norm)  \n",
    "\n",
    "        # Tokenize and rank genes for each cell in chunk\n",
    "        for i in range(X_norm.shape[0]):\n",
    "            ranks = rank_genes(X_norm[i].data, coding_miRNA_tokens[X_norm[i].indices])\n",
    "            ranks = list(ranks[~np.isnan(ranks)].astype(int))\n",
    "\n",
    "            tokenized_cells.append(ranks)\n",
    "\n",
    "        # Update metadata\n",
    "        for k in adata.obs.columns:\n",
    "            file_cell_metadata[k].extend(adata_chunk.obs[k].tolist())\n",
    "\n",
    "    return tokenized_cells, file_cell_metadata\n",
    "\n",
    "\n",
    "tokenized_cells, cell_metadata = tokenize_anndata(adata, genelist_dict, gene_median_dict)\n",
    "print(len(tokenized_cells))\n",
    "print(tokenized_cells[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319023d2-8458-43fc-b359-f4fc08f0c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace4b1e-0abd-4734-95b7-7a4991e8b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(tokenized_cells, cell_metadata, gene_token_dict, model_input_size=2048, nproc=16):\n",
    "    \"\"\"\n",
    "    Creates a Hugging Face Dataset from tokenized cells and associated metadata.\n",
    "\n",
    "    Args:\n",
    "        tokenized_cells (list): List of tokenized cell representations (lists of tokens).\n",
    "        cell_metadata (dict, optional): Dictionary containing additional cell metadata.\n",
    "        model_input_size (int): The maximum input size for the model.\n",
    "        gene_token_dict (dict): Dictionary mapping genes to their tokens.\n",
    "        nproc (int, optional): Number of processes to use for mapping. Defaults to 16.\n",
    "\n",
    "    Returns:\n",
    "        datasets.Dataset: The processed Hugging Face dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Merge cell metadata into the dataset dictionary if provided\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": tokenized_cells,\n",
    "        **cell_metadata \n",
    "    }\n",
    "    \n",
    "    output_dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "    def format_cell_features(example):\n",
    "        example[\"input_ids\"] = example[\"input_ids\"][0 : model_input_size] # truncate\n",
    "        example[\"length\"] = len(example[\"input_ids\"])  # Add length for convenience\n",
    "        return example\n",
    "\n",
    "    return output_dataset.map(format_cell_features, num_proc=nproc)  # Return mapped dataset\n",
    "\n",
    "dataset = create_dataset(tokenized_cells, cell_metadata, gene_token_dict)\n",
    "type(dataset)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f816c6a-635e-40c9-b99b-18403fa57fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081a475-2fcc-417d-84bc-b73d24031811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hf_dataset(dataset: Dataset, output_directory: str, output_prefix: str, overwrite=False):\n",
    "    \"\"\"\n",
    "    Saves a Hugging Face Dataset to disk in a specified directory.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): The Hugging Face Dataset to be saved.\n",
    "        output_directory (str): The directory where the dataset will be saved.\n",
    "        output_prefix (str): The prefix for the dataset filename.\n",
    "        overwrite (bool, optional): Whether to overwrite an existing dataset. Defaults to False.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the dataset is not a Hugging Face Dataset instance.\n",
    "        FileExistsError: If a dataset with the same name exists and `overwrite` is False.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(dataset, Dataset):\n",
    "        raise TypeError(\"The provided dataset is not a Hugging Face Dataset.\")\n",
    "\n",
    "    output_path = os.path.join(output_directory, f\"{output_prefix}.dataset\")\n",
    "\n",
    "    if os.path.exists(output_path) and not overwrite:\n",
    "        raise FileExistsError(\n",
    "            f\"Dataset '{output_path}' already exists. Set `overwrite=True` to overwrite.\"\n",
    "        )\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    dataset.save_to_disk(output_path)\n",
    "    \n",
    "output_directory = \"/scratch/indikar_root/indikar1/cstansbu/geneformer/\"\n",
    "output_prefix = \"test\"\n",
    "save_hf_dataset(dataset, output_directory, output_prefix, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1172e74-6245-4f70-8d70-2cc5b6528025",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e6df9-c976-444c-8c56-f2cc110e73ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe0858-8fd7-4ace-8638-5165eb82e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (Path(output_directory) / output_prefix).with_suffix(\".dataset\")\n",
    "tokenized_dataset.save_to_disk(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d7652-f0a8-4912-aeb9-cb1fbb80f571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a4ac5-65f2-47ee-a66d-280208a67e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_cells[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ae543-9906-43b3-914f-8aaf77e9a032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3257e4c-3ba1-4907-bca5-d91c7a191b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108d0ef-c9fb-4af2-9899-f414adf3f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b5c79b-6d80-4ebe-8647-d15043686c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.obs['n_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec23be8-f785-477e-986f-93ace7b9b25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d1728-d045-4472-93fa-472da6dea15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bf61f-5c5e-4a24-b3e6-3da8e05bc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['predicted_doublet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452227a1-1ff3-40d0-9a21-881feeadcdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"doublet_score\", \"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"],\n",
    "    size=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a8032-6155-4c8e-aa4f-1e5d27cae07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"r12\", \"r16\", \"r97\"],\n",
    "    size=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6fb50-aa1c-4901-876e-981349cdb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var[['gene_name', 'means', 'dispersions']].sort_values(by='means', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8d0526-4e17-4b44-9e94-83fe37981f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?sc.pl.umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482814d4-e618-43da-93b3-7d52b5a0bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=[\"KLF2\", \"FSTL1\", \"GATA2\", \"FOXL2NB\"],\n",
    "    size=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b10d32-a9c9-40df-95f1-0e33b8c9c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=[\"MPL\", \"CD34\", \"MGST1\", \"PTPRC\"],\n",
    "    size=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447d7c9-8d36-48f9-9711-0d4a7b5640f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=[\"GATA2\", \"FOS\", \"STAT5A\", \"REL\", \"GFI1B\"],\n",
    "    size=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe35ef2-e6a5-41c2-aaa9-e4a4ed36b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205346a9-1679-458e-8ebe-65c66dbdd7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8df7f8-2fe0-414f-a97d-c097bd1c21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 25\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=adata.uns['fb_vs_hsc_up']['gene_name'].head(n).unique(),\n",
    "    size=25,\n",
    ")\n",
    "\n",
    "adata.uns['fb_vs_hsc_up'].head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128548e-f003-4c1e-89d4-a179dddfffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 25\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=adata.uns['hsc_v_fib_up']['gene_name'].head(n).unique(),\n",
    "    size=25,\n",
    ")\n",
    "\n",
    "adata.uns['hsc_v_fib_up'].head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f436ea1-2902-48d2-91bd-4c4035546897",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=adata.uns['panglaodb']['gene_name'].head(n).unique(),\n",
    "    size=25,\n",
    ")\n",
    "\n",
    "adata.uns['panglaodb'].head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7c3a1-4d28-4759-bd39-70d9c5d24e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=adata.uns['tabula_sapiens_deg']['gene_name'].head(10).unique(),\n",
    "    size=25,\n",
    ")\n",
    "\n",
    "adata.uns['tabula_sapiens_deg'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00716fe-83a3-40eb-b327-c1a1e477ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=adata.uns['tabula_sapiens_deg']['gene_name'].tail(10).unique(),\n",
    "    size=25,\n",
    ")\n",
    "\n",
    "adata.uns['tabula_sapiens_deg'].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8ecb8-ed9a-4042-aef7-01912a32bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=adata.uns['go_annotations']['gene_name'].unique(),\n",
    "    size=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688b382-221f-4680-8fcc-2940c246f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3eede9-d86c-4e4a-b71d-29857d9151fd",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf6d95-5a56-4b53-824e-280a0c768031",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7dd97-830d-42f2-9b85-e0f9534005bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path\n",
    "dpath = \"../config/gene_annotations/\"\n",
    "\n",
    "gene_map = dict(zip(adata.var['gene_name'].values, adata.var['ensembl_id'].values))\n",
    "\n",
    "\n",
    "for f in os.listdir(dpath):\n",
    "    if not f.endswith(\".csv\"):\n",
    "        continue\n",
    "        \n",
    "    # load the annotation\n",
    "    fpath = f\"{dpath}{f}\"    \n",
    "    df = pd.read_csv(fpath)\n",
    "    \n",
    "    # make a key name\n",
    "    key_name = f.replace(\".csv\", \"\")\n",
    "        \n",
    "    # map ensemble_ids, drop unseen genes\n",
    "    df['gene_name'] = df['gene_name'].astype(str).str.upper()\n",
    "    df = df[df['gene_name'].isin(list(gene_map.keys()))]\n",
    "    df['ensembl_id'] = df['gene_name'].map(gene_map)\n",
    "    \n",
    "    adata.uns[key_name] = df\n",
    "    \n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f6265-5dde-46c3-b4d1-5251cdc586da",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['tabula_sapiens_deg'].query(\"cell_type == 'hematopoietic stem cell' and pct_nz_group > 0.9 and pvals_adj > 0\").sort_values(by='logfoldchanges').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ad17a-688d-4c36-bcc7-ded2d2328de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=[\"FSTL1\", \"JUNB\", \"RHOA\", \"MGST1\", \"NOP53\", \"ADGRG1\"],\n",
    "    size=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dc6f9-70c0-4bba-97ca-c3aec92b521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['go_annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d733718-f21a-497c-bf77-4b24f12e9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    gene_symbols='gene_name',\n",
    "    color=adata.uns['go_annotations']['gene_name'].to_list(),\n",
    "    size=25,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3925b3b-7a70-4e35-9a48-a99e41133891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b2bf9-fd9c-45b5-a5c3-4341e0cf7afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d904eae-7aa9-4560-afcb-f4ae0ca271fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
